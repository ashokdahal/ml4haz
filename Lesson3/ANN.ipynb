{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir Dataset\n",
    "!wget  https://zenodo.org/records/12747177/files/FloodData.gpkg?download=1  -O Dataset/FloodData.gpkg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import layers, optimizers, losses, metrics, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "df = gpd.read_file(\"Dataset/FloodData.gpkg\")\n",
    "constcols = [\"Est_m\", \"Nrt_m\", \"HC_m\", \"VC_m\", \"Slp_m\", \"Prc_m\", \"NDVI_m\", \"SoilInfilt\"]\n",
    "Xdata = df[constcols].to_numpy()\n",
    "Ydata = df.Flood.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize Data\n",
    "max = Xdata.max(axis=0)\n",
    "min = Xdata.min(axis=0)\n",
    "norm_xdata = (Xdata - min) / (max - min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FloodModel:\n",
    "    def __init__(self):\n",
    "        self.depth = 12\n",
    "\n",
    "    def getclassificationModel(self, in_num=17, out_num=1):\n",
    "        features_only = Input((in_num))\n",
    "\n",
    "        x = layers.Dense(\n",
    "            units=64,\n",
    "            name=f\"Sus_0\",\n",
    "            kernel_initializer=\"random_normal\",\n",
    "            bias_initializer=\"random_normal\",\n",
    "        )(features_only)\n",
    "        for i in range(1, self.depth + 1):\n",
    "            x = layers.Dense(\n",
    "                units=64,\n",
    "                name=f\"Sus_{str(i)}\",\n",
    "                kernel_initializer=\"random_normal\",\n",
    "                bias_initializer=\"random_normal\",\n",
    "            )(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "            x = layers.Activation(\"relu\")(x)\n",
    "            # x= layers.Dropout(.3)(x)\n",
    "\n",
    "        out_areaDen = layers.Dense(units=out_num, activation=\"sigmoid\", name=\"sus\")(x)\n",
    "        self.model = Model(inputs=features_only, outputs=out_areaDen)\n",
    "\n",
    "    def getOptimizer(\n",
    "        self, opt=tf.keras.optimizers.Adam, lr=1e-3, decay_steps=10000, decay_rate=0.9\n",
    "    ):\n",
    "        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "            initial_learning_rate=lr, decay_steps=decay_steps, decay_rate=decay_rate\n",
    "        )\n",
    "        self.optimizer = opt(learning_rate=lr_schedule)\n",
    "\n",
    "    def compileModel(self, weights=None):\n",
    "        self.model.compile(\n",
    "            optimizer=self.optimizer,\n",
    "            loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "            metrics=[\n",
    "                tf.keras.metrics.BinaryIoU(target_class_ids=[0, 1], threshold=0.5),\n",
    "                tf.keras.metrics.AUC(),\n",
    "                tf.keras.metrics.BinaryAccuracy(),\n",
    "            ],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "clfmdl = FloodModel()\n",
    "clfmdl.getclassificationModel(in_num=8, out_num=1)\n",
    "clfmdl.getOptimizer()\n",
    "clfmdl.compileModel()\n",
    "# print(clfmdl.model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    norm_xdata, Ydata, test_size=0.30, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainmodel(model, xdata, ydata):\n",
    "    NUMBER_EPOCHS = 100\n",
    "    filepath = \"checkpointsUSGSv2\"\n",
    "    BATCH_SIZE = 32\n",
    "\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath,\n",
    "        monitor=\"val_auc\",\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        mode=\"max\",\n",
    "        save_freq=\"epoch\",\n",
    "        options=None,\n",
    "    )\n",
    "    print(type(xdata), type(ydata))\n",
    "    hist = model.fit(\n",
    "        x=xdata,\n",
    "        y=ydata,\n",
    "        epochs=NUMBER_EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_split=0.2,  # auto validate using 20% of random samples at each epoch\n",
    "        verbose=1,\n",
    "        callbacks=[model_checkpoint_callback],\n",
    "        class_weight={0: 1, 1: 5},\n",
    "    )\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainmodel(\n",
    "    clfmdl.model,\n",
    "    np.array(X_train, dtype=np.float32),\n",
    "    np.expand_dims(np.array(y_train, dtype=np.float32), axis=-1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict in test set\n",
    "preds = clfmdl.model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fpr, tpr, thresholds = sklearn.metrics.roc_curve(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sklearn.metrics.auc(fpr, tpr))\n",
    "print(sklearn.metrics.confusion_matrix(y_test, np.rint(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2 = preds\n",
    "preds2[preds > 0.80] = 1\n",
    "preds2[preds <= 0.80] = 0\n",
    "sklearn.metrics.accuracy_score(y_test, preds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(\n",
    "    fpr,\n",
    "    tpr,\n",
    "    color=\"darkorange\",\n",
    "    lw=lw,\n",
    "    label=\"ROC curve (area = %0.2f)\" % 0.8577,\n",
    ")\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve Flood Classification\")\n",
    "plt.text(0.61, 0.15, \"Accuracy=0.8131\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"roc.pdf\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
