{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ta50fzN_1twO"
   },
   "source": [
    "## Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j25EcJhx1twO",
    "outputId": "ef95797e-7187-47ed-cd91-80a6b343cd34"
   },
   "outputs": [],
   "source": [
    "!mkdir Dataset\n",
    "!wget  https://zenodo.org/records/7189381/files/trainX.npy?download=1  -O Dataset/Xdata.npy\n",
    "!wget  https://zenodo.org/records/7189381/files/trainY.npy?download=1  -O Dataset/Ydata.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKgI8dJ61twP"
   },
   "source": [
    "## Prepare paths of input images and target segmentation masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EmMMFiA91twP",
    "outputId": "139385d6-9736-47d1-e510-1eb1653f32d3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdata = np.load(\"Dataset/Xdata.npy\")\n",
    "Ydata = np.load(\"Dataset/Ydata.npy\")\n",
    "print(f\"the shape of input image matrix is {Xdata.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RyhjKG0n1twP"
   },
   "source": [
    "## What does one input image and corresponding segmentation mask look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 913
    },
    "id": "_LeTw2f31twP",
    "outputId": "2ad576d3-b47f-4ad8-c878-b0a061daa6de"
   },
   "outputs": [],
   "source": [
    "n = 289  # sample number\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax[0].imshow(Xdata[n, :, :, :3].transpose((0, 1, 2)))\n",
    "ax[1].imshow(Ydata[n, :, :, 0])\n",
    "\n",
    "ax[0].ticklabel_format(useOffset=False, style=\"plain\")\n",
    "ax[1].ticklabel_format(useOffset=False, style=\"plain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Si-41UdN1twP"
   },
   "source": [
    "## Prepare dataset to train validate and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JT9WQSgV1twP"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    Xdata, Ydata, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWYg0nXN1twQ"
   },
   "source": [
    "## Prepare U-Net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6D3nz91Z1twQ",
    "outputId": "ed74aac0-df89-4e21-de50-939dfc3d4335"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.activations import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "def down_block(x, filters, use_maxpool=True):\n",
    "    x = Conv2D(filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Conv2D(filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    if use_maxpool == True:\n",
    "        return MaxPooling2D(strides=(2, 2))(x), x\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "def up_block(x, y, filters):\n",
    "    x = UpSampling2D()(x)\n",
    "    x = Concatenate(axis=3)([x, y])\n",
    "    x = Conv2D(filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Conv2D(filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_model(input_size=(256, 256, 3), *, classes, dropout):\n",
    "    filter = [64, 128, 256, 512, 1024]\n",
    "    # encode\n",
    "    input = Input(shape=input_size)\n",
    "    x, temp1 = down_block(input, filter[0])\n",
    "    x, temp2 = down_block(x, filter[1])\n",
    "    x, temp3 = down_block(x, filter[2])\n",
    "    x, temp4 = down_block(x, filter[3])\n",
    "    x = down_block(x, filter[4], use_maxpool=False)\n",
    "    # decode\n",
    "    x = up_block(x, temp4, filter[3])\n",
    "    x = up_block(x, temp3, filter[2])\n",
    "    x = up_block(x, temp2, filter[1])\n",
    "    x = up_block(x, temp1, filter[0])\n",
    "    x = Dropout(dropout)(x)\n",
    "    output = Conv2D(classes, 1, activation=\"sigmoid\")(x)\n",
    "    model = models.Model(input, output, name=\"unet\")\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "# Build model\n",
    "model = get_model(input_size=(128, 128, 4), classes=1, dropout=0.2)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qsXfVKxR1twQ"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 668
    },
    "id": "IbwPPdV31twQ",
    "outputId": "27bf3549-858e-41ae-cb44-357ab62f29ea"
   },
   "outputs": [],
   "source": [
    "# Compile model for training\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-4),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        tf.keras.metrics.AUC(),\n",
    "        tf.keras.metrics.MeanIoU(num_classes=2),\n",
    "        tf.keras.metrics.Precision(),\n",
    "        tf.keras.metrics.Recall(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "def trainmodel(model, xdata, ydata):\n",
    "    NUMBER_EPOCHS = 10\n",
    "    filepath = \"checkpointMaping\"\n",
    "    BATCH_SIZE = 32\n",
    "\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath,\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        mode=\"min\",\n",
    "        save_freq=\"epoch\",\n",
    "        options=None,\n",
    "    )\n",
    "    print(type(xdata), type(ydata))\n",
    "    hist = model.fit(\n",
    "        x=xdata,\n",
    "        y=ydata,\n",
    "        epochs=NUMBER_EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_split=0.2,  # auto validate using 20% of random samples at each epoch\n",
    "        verbose=1,\n",
    "        callbacks=[model_checkpoint_callback],\n",
    "        class_weight={0: 1, 1: 5},\n",
    "    )\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainmodel(\n",
    "    model,\n",
    "    np.array(X_train, dtype=np.float32),\n",
    "    np.expand_dims(np.array(y_train, dtype=np.float32), axis=-1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tfl1RO571twQ"
   },
   "source": [
    "## Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y9hNjwhT1twQ"
   },
   "outputs": [],
   "source": [
    "# Generate predictions for all images in the validation set\n",
    "\n",
    "val_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = val_preds\n",
    "preds[preds > 0.50] = 1\n",
    "preds[preds <= 0.50] = 0\n",
    "sklearn.metrics.accuracy_score(y_test.flatten(), preds.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = val_preds\n",
    "preds[preds > 0.50] = 1\n",
    "preds[preds <= 0.50] = 0\n",
    "sklearn.metrics.f1_score(y_test.flatten(), preds.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "et_algmI10Gt"
   },
   "outputs": [],
   "source": [
    "n = 235  # sample number\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "im1 = ax[0].imshow(\n",
    "    val_preds[n, :, :, :3].transpose((0, 1, 2)), vmin=0, vmax=0.5, cmap=\"plasma\"\n",
    ")\n",
    "im2 = ax[1].imshow(y_test[n, :, :, 0], cmap=\"plasma\")\n",
    "ax[0].ticklabel_format(useOffset=False, style=\"plain\")\n",
    "ax[1].ticklabel_format(useOffset=False, style=\"plain\")\n",
    "\n",
    "fig.colorbar(im1, ax=ax[0])\n",
    "fig.colorbar(im2, ax=ax[1])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CNN for Disaster Mapping",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
